{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline \n",
    "按照如下的指导要求，搭建你的机器学习管道。\n",
    "### 1. 导入与加载\n",
    "- 导入 Python 库\n",
    "- 使用 [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html) 从数据库中加载数据集\n",
    "- 定义特征变量X 和目标变量 Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, fbeta_score, make_scorer,confusion_matrix,classification_report,fbeta_score,make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn import multioutput\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterData.db')\n",
    "df = pd.read_sql_table('DisasterData',engine)\n",
    "X = df.message.values\n",
    "y = df.iloc[:,4:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 编写分词函数，开始处理文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    stop_words = stopwords.words(\"english\")\n",
    "        \n",
    "    tokens = [WordNetLemmatizer().lemmatize(word) for word in words if word not in stop_words]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 创建机器学习管道 \n",
    "这个机器学习管道应该接收 `message` 列作输入，输出分类结果，分类结果属于该数据集中的 36 个类。你会发现 [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) 在预测多目标变量时很有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('transformer', TfidfTransformer()),\n",
    "        ('clf', multioutput.MultiOutputClassifier(DecisionTreeClassifier(random_state=10),n_jobs=-1))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 训练管道\n",
    "- 将数据分割成训练和测试集\n",
    "- 训练管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13193,), (13193, 36))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state = 10)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "       ...tion_leaf=0.0, presort=False, random_state=10,\n",
       "            splitter='best'),\n",
       "           n_jobs=-1))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 测试模型\n",
    "报告数据集中每个输出类别的 f1 得分、准确度和召回率。你可以对列进行遍历，并对每个元素调用 sklearn 的 `classification_report`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.49      0.51      3077\n",
      "          1       0.85      0.85      0.85     10016\n",
      "          2       0.14      0.39      0.21       100\n",
      "\n",
      "avg / total       0.77      0.76      0.77     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.92      0.91     10922\n",
      "          1       0.59      0.55      0.57      2271\n",
      "\n",
      "avg / total       0.85      0.86      0.86     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     13124\n",
      "          1       0.04      0.03      0.03        69\n",
      "\n",
      "avg / total       0.99      0.99      0.99     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.77      0.76      7691\n",
      "          1       0.66      0.64      0.65      5502\n",
      "\n",
      "avg / total       0.71      0.71      0.71     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.95      0.95     12152\n",
      "          1       0.37      0.34      0.35      1041\n",
      "\n",
      "avg / total       0.90      0.90      0.90     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97     12501\n",
      "          1       0.40      0.37      0.38       692\n",
      "\n",
      "avg / total       0.94      0.94      0.94     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98     12829\n",
      "          1       0.25      0.22      0.23       364\n",
      "\n",
      "avg / total       0.96      0.96      0.96     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98     12965\n",
      "          1       0.08      0.08      0.08       228\n",
      "\n",
      "avg / total       0.97      0.97      0.97     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98     12748\n",
      "          1       0.37      0.36      0.36       445\n",
      "\n",
      "avg / total       0.96      0.96      0.96     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     13193\n",
      "\n",
      "avg / total       1.00      1.00      1.00     13193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "for i in range(10):\n",
    "    print(classification_report(y_test[:,i],y_pred[:,i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.764875312666\n",
      "0.858030773895\n",
      "0.991510649587\n",
      "0.711286288183\n",
      "0.901690290305\n",
      "0.938149018419\n",
      "0.960130372167\n",
      "0.96861972258\n",
      "0.957780641249\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(accuracy_score(y_test[:,i],y_pred[:,i]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 优化模型\n",
    "使用网格搜索来找到最优的参数组合。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vectorizer',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "           strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=<function tokenize at 0x7ff5ee3a7620>, vocabulary=None)),\n",
       "  ('transformer',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       "  ('clf',\n",
       "   MultiOutputClassifier(estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "               max_features=None, max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
       "               splitter='best'),\n",
       "              n_jobs=-1))],\n",
       " 'vectorizer': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=<function tokenize at 0x7ff5ee3a7620>, vocabulary=None),\n",
       " 'transformer': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'clf': MultiOutputClassifier(estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
       "             splitter='best'),\n",
       "            n_jobs=-1),\n",
       " 'vectorizer__analyzer': 'word',\n",
       " 'vectorizer__binary': False,\n",
       " 'vectorizer__decode_error': 'strict',\n",
       " 'vectorizer__dtype': numpy.int64,\n",
       " 'vectorizer__encoding': 'utf-8',\n",
       " 'vectorizer__input': 'content',\n",
       " 'vectorizer__lowercase': True,\n",
       " 'vectorizer__max_df': 1.0,\n",
       " 'vectorizer__max_features': None,\n",
       " 'vectorizer__min_df': 1,\n",
       " 'vectorizer__ngram_range': (1, 1),\n",
       " 'vectorizer__preprocessor': None,\n",
       " 'vectorizer__stop_words': None,\n",
       " 'vectorizer__strip_accents': None,\n",
       " 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vectorizer__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vectorizer__vocabulary': None,\n",
       " 'transformer__norm': 'l2',\n",
       " 'transformer__smooth_idf': True,\n",
       " 'transformer__sublinear_tf': False,\n",
       " 'transformer__use_idf': True,\n",
       " 'clf__estimator__class_weight': None,\n",
       " 'clf__estimator__criterion': 'gini',\n",
       " 'clf__estimator__max_depth': None,\n",
       " 'clf__estimator__max_features': None,\n",
       " 'clf__estimator__max_leaf_nodes': None,\n",
       " 'clf__estimator__min_impurity_decrease': 0.0,\n",
       " 'clf__estimator__min_impurity_split': None,\n",
       " 'clf__estimator__min_samples_leaf': 1,\n",
       " 'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__estimator__presort': False,\n",
       " 'clf__estimator__random_state': 10,\n",
       " 'clf__estimator__splitter': 'best',\n",
       " 'clf__estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
       "             splitter='best'),\n",
       " 'clf__n_jobs': -1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "             'clf__estimator__min_samples_split':[3,4]\n",
    "             }\n",
    "\n",
    "cv = GridSearchCV(pipeline, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "       ...tion_leaf=0.0, presort=False, random_state=10,\n",
       "            splitter='best'),\n",
       "           n_jobs=-1))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'clf__estimator__min_samples_split': [3, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16789206397331918"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 测试模型\n",
    "打印微调后的模型的精确度、准确率和召回率。  \n",
    "\n",
    "因为本项目主要关注代码质量、开发流程和管道技术，所有没有模型性能指标的最低要求。但是，微调模型提高精确度、准确率和召回率可以让你的项目脱颖而出——特别是让你的简历更出彩。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.49      0.51      3077\n",
      "          1       0.85      0.86      0.85     10016\n",
      "          2       0.15      0.42      0.23       100\n",
      "\n",
      "avg / total       0.77      0.77      0.77     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.92      0.91     10922\n",
      "          1       0.59      0.54      0.56      2271\n",
      "\n",
      "avg / total       0.85      0.86      0.85     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     13124\n",
      "          1       0.05      0.03      0.04        69\n",
      "\n",
      "avg / total       0.99      0.99      0.99     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.76      0.75      7691\n",
      "          1       0.66      0.63      0.64      5502\n",
      "\n",
      "avg / total       0.71      0.71      0.71     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.95      0.95     12152\n",
      "          1       0.37      0.34      0.35      1041\n",
      "\n",
      "avg / total       0.90      0.90      0.90     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97     12501\n",
      "          1       0.41      0.36      0.38       692\n",
      "\n",
      "avg / total       0.94      0.94      0.94     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98     12829\n",
      "          1       0.27      0.24      0.25       364\n",
      "\n",
      "avg / total       0.96      0.96      0.96     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99     12965\n",
      "          1       0.09      0.08      0.09       228\n",
      "\n",
      "avg / total       0.97      0.97      0.97     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98     12748\n",
      "          1       0.38      0.38      0.38       445\n",
      "\n",
      "avg / total       0.96      0.96      0.96     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     13193\n",
      "\n",
      "avg / total       1.00      1.00      1.00     13193\n",
      "\n",
      "0.766163874782\n",
      "0.855150458577\n",
      "0.992117031759\n",
      "0.708860759494\n",
      "0.902220874706\n",
      "0.939134389449\n",
      "0.961343136512\n",
      "0.97104525127\n",
      "0.95831122565\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = cv.predict(X_test)\n",
    "\n",
    "for i in range(10):\n",
    "    print(classification_report(y_test[:,i],y_pred[:,i]) )\n",
    "for i in range(10):\n",
    "    print(accuracy_score(y_test[:,i],y_pred[:,i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16789206397331918"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 继续优化模型，比如：\n",
    "* 尝试其他的机器学习算法\n",
    "* 尝试除 TF-IDF 外其他的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "       ...ob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=-1))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2 = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('transformer', TfidfTransformer()),\n",
    "        ('clf', multioutput.MultiOutputClassifier(RandomForestClassifier(),n_jobs=-1))\n",
    "      ])\n",
    "\n",
    "pipeline2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.44      0.51      3077\n",
      "          1       0.84      0.91      0.87     10016\n",
      "          2       0.39      0.26      0.31       100\n",
      "\n",
      "avg / total       0.78      0.80      0.78     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93     10922\n",
      "          1       0.77      0.44      0.56      2271\n",
      "\n",
      "avg / total       0.87      0.88      0.87     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     13124\n",
      "          1       1.00      0.03      0.06        69\n",
      "\n",
      "avg / total       0.99      0.99      0.99     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.85      0.80      7691\n",
      "          1       0.75      0.62      0.68      5502\n",
      "\n",
      "avg / total       0.75      0.75      0.75     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96     12152\n",
      "          1       0.56      0.08      0.15      1041\n",
      "\n",
      "avg / total       0.90      0.92      0.90     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97     12501\n",
      "          1       0.73      0.08      0.15       692\n",
      "\n",
      "avg / total       0.94      0.95      0.93     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99     12829\n",
      "          1       0.64      0.10      0.17       364\n",
      "\n",
      "avg / total       0.97      0.97      0.96     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99     12965\n",
      "          1       0.30      0.01      0.03       228\n",
      "\n",
      "avg / total       0.97      0.98      0.97     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98     12748\n",
      "          1       0.74      0.11      0.19       445\n",
      "\n",
      "avg / total       0.96      0.97      0.96     13193\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     13193\n",
      "\n",
      "avg / total       1.00      1.00      1.00     13193\n",
      "\n",
      "0.797619949973\n",
      "0.88084590313\n",
      "0.994921549306\n",
      "0.754263624649\n",
      "0.922458879709\n",
      "0.950352459638\n",
      "0.973622375502\n",
      "0.982414917001\n",
      "0.968695520352\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = pipeline2.predict(X_test)\n",
    "\n",
    "for i in range(10):\n",
    "    print(classification_report(y_test[:,i], y_pred2[:,i]))\n",
    "for i in range(10):\n",
    "    print(accuracy_score(y_test[:,i],y_pred2[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 导出模型为 pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pipeline, open('model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "使用资源 (Resources)文件里附带的模板文件编写脚本，运行上述步骤，创建一个数据库，并基于用户指定的新数据集输出一个模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
